{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans","metadata":{"execution":{"iopub.status.busy":"2023-03-20T00:15:11.243112Z","iopub.execute_input":"2023-03-20T00:15:11.243655Z","iopub.status.idle":"2023-03-20T00:15:22.278958Z","shell.execute_reply.started":"2023-03-20T00:15:11.243613Z","shell.execute_reply":"2023-03-20T00:15:22.277266Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"TFIDF vectorizer","metadata":{}},{"cell_type":"code","source":"# Using Tfidf vectorizer on the original data\n\ndata = pd.read_csv('/kaggle/input/fake-reviews-swm/fake reviews dataset.csv')\ntexts = data['text_'].tolist()\n\n# Extract features\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(texts)\n\n# Perform clustering using KMeans\nkmeans = KMeans(n_clusters=2, random_state=2)\ny_pred = kmeans.fit_predict(X)\n\nsum_1 = 0\ncount_sum_1 = 0\nsum_0 = 0\ncount_sum_0 = 0\nfor i in range(len(y_pred)):\n    if y_pred[i] == 1:\n        sum_1 = sum_1 + data['rating'][i]\n        count_sum_1 = count_sum_1 + 1\n    else:\n        sum_0 = sum_0 + data['rating'][i]\n        count_sum_0 = count_sum_0 + 1\n\nprint(\"avg. rating for 1: \", (sum_1/count_sum_1))\nprint(\"avg. rating for 0: \", (sum_0/count_sum_0))","metadata":{"execution":{"iopub.status.busy":"2023-03-18T22:19:32.035006Z","iopub.execute_input":"2023-03-18T22:19:32.035889Z","iopub.status.idle":"2023-03-18T22:19:41.687291Z","shell.execute_reply.started":"2023-03-18T22:19:32.035836Z","shell.execute_reply":"2023-03-18T22:19:41.685820Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"avg. rating for 1:  4.251649519123239\navg. rating for 0:  4.294382504288165\n","output_type":"stream"}]},{"cell_type":"code","source":"# Using Tfidf vectorizer on the new data\n\ndata = pd.read_csv('/kaggle/input/new-fake-reviews-swm/new_fake_reviews_data.csv')\ntexts = data['text_'].tolist()\n\n# Extract features\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(texts)\n\n# Perform clustering using KMeans\nkmeans = KMeans(n_clusters=2, random_state=2)\ny_pred = kmeans.fit_predict(X)\n\nsum_1 = 0\ncount_sum_1 = 0\nsum_0 = 0\ncount_sum_0 = 0\nfor i in range(len(y_pred)):\n    if y_pred[i] == 1:\n        sum_1 = sum_1 + data['rating'][i]\n        count_sum_1 = count_sum_1 + 1\n    else:\n        sum_0 = sum_0 + data['rating'][i]\n        count_sum_0 = count_sum_0 + 1\n\nprint(\"avg. rating for 1: \", (sum_1/count_sum_1))\nprint(\"avg. rating for 0: \", (sum_0/count_sum_0))","metadata":{"execution":{"iopub.status.busy":"2023-03-18T22:21:42.774490Z","iopub.execute_input":"2023-03-18T22:21:42.775320Z","iopub.status.idle":"2023-03-18T22:21:49.685701Z","shell.execute_reply.started":"2023-03-18T22:21:42.775273Z","shell.execute_reply":"2023-03-18T22:21:49.683979Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"avg. rating for 1:  4.112971194365872\navg. rating for 0:  4.3584317798260415\n","output_type":"stream"}]},{"cell_type":"markdown","source":"BERT embeddings and kmeans clustering","metadata":{}},{"cell_type":"code","source":"# Using BERT embeddings on the original data\n\ndata = pd.read_csv('/kaggle/input/fake-reviews-swm/fake reviews dataset.csv')\ntexts = data['text_'][:4000].tolist()\n\n# Load pre-trained BERT model\nmodule_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\nembed = hub.KerasLayer(module_url, trainable=False)\n\n# Extract BERT embeddings\nX = embed(texts).numpy()\n\n# Cluster data\nkmeans = KMeans(n_clusters=2, random_state=2)\ny_pred = kmeans.fit_predict(X)\n\nsum_1 = 0\ncount_sum_1 = 0\nsum_0 = 0\ncount_sum_0 = 0\nfor i in range(len(y_pred)):\n    if y_pred[i] == 1:\n        sum_1 = sum_1 + data['rating'][i]\n        count_sum_1 = count_sum_1 + 1\n    else:\n        sum_0 = sum_0 + data['rating'][i]\n        count_sum_0 = count_sum_0 + 1\n\nprint(\"avg. rating for 1: \", (sum_1/count_sum_1))\nprint(\"avg. rating for 0: \", (sum_0/count_sum_0))","metadata":{"execution":{"iopub.status.busy":"2023-03-18T22:36:27.459182Z","iopub.execute_input":"2023-03-18T22:36:27.459715Z","iopub.status.idle":"2023-03-18T22:42:20.423922Z","shell.execute_reply.started":"2023-03-18T22:36:27.459675Z","shell.execute_reply":"2023-03-18T22:42:20.422378Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"avg. rating for 1:  4.292486942547208\navg. rating for 0:  4.180675049636003\n","output_type":"stream"}]},{"cell_type":"code","source":"# Using BERT embeddings on the new data\n\ndata = pd.read_csv('/kaggle/input/new-fake-reviews-swm/new_fake_reviews_data.csv')\ntexts = data['text_'][:4000].tolist()\n\n# Load pre-trained BERT model\nmodule_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\nembed = hub.KerasLayer(module_url, trainable=False)\n\n# Extract BERT embeddings\nX = embed(texts).numpy()\n\n# Cluster data\nkmeans = KMeans(n_clusters=2, random_state=2)\ny_pred = kmeans.fit_predict(X)\n\nsum_1 = 0\ncount_sum_1 = 0\nsum_0 = 0\ncount_sum_0 = 0\nfor i in range(len(y_pred)):\n    if y_pred[i] == 1:\n        sum_1 = sum_1 + data['rating'][i]\n        count_sum_1 = count_sum_1 + 1\n    else:\n        sum_0 = sum_0 + data['rating'][i]\n        count_sum_0 = count_sum_0 + 1\n\nprint(\"avg. rating for 1: \", (sum_1/count_sum_1))\nprint(\"avg. rating for 0: \", (sum_0/count_sum_0))","metadata":{"execution":{"iopub.status.busy":"2023-03-19T19:46:30.946208Z","iopub.execute_input":"2023-03-19T19:46:30.946989Z","iopub.status.idle":"2023-03-19T19:53:02.299300Z","shell.execute_reply.started":"2023-03-19T19:46:30.946946Z","shell.execute_reply":"2023-03-19T19:53:02.297569Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"avg. rating for 1:  4.2683544303797465\navg. rating for 0:  4.232326820603908\n","output_type":"stream"}]},{"cell_type":"markdown","source":"BERT embeddings and kmeans clustering with PCA","metadata":{}},{"cell_type":"code","source":"# Using BERT embeddings on the original data\n\nfrom sklearn.decomposition import PCA\n\ndata = pd.read_csv('/kaggle/input/fake-reviews-swm/fake reviews dataset.csv')\ntexts = data['text_'][:4000].tolist()\n\n# Load pre-trained BERT model\nmodule_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\nembed = hub.KerasLayer(module_url, trainable=False)\n\n# Extract BERT embeddings\nX = embed(texts).numpy()\n\n# Using PCA\npca = PCA(n_components=50)\nX = pca.fit_transform(X)\n\n# Cluster data\nkmeans = KMeans(n_clusters=2, random_state=2)\ny_pred = kmeans.fit_predict(X)\n\nsum_1 = 0\ncount_sum_1 = 0\nsum_0 = 0\ncount_sum_0 = 0\nfor i in range(len(y_pred)):\n    if y_pred[i] == 1:\n        sum_1 = sum_1 + data['rating'][i]\n        count_sum_1 = count_sum_1 + 1\n    else:\n        sum_0 = sum_0 + data['rating'][i]\n        count_sum_0 = count_sum_0 + 1\n\nprint(\"avg. rating for 1: \", (sum_1/count_sum_1))\nprint(\"avg. rating for 0: \", (sum_0/count_sum_0))","metadata":{"execution":{"iopub.status.busy":"2023-03-20T01:55:17.261530Z","iopub.execute_input":"2023-03-20T01:55:17.262098Z","iopub.status.idle":"2023-03-20T02:01:17.926732Z","shell.execute_reply.started":"2023-03-20T01:55:17.262054Z","shell.execute_reply":"2023-03-20T02:01:17.924994Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"avg. rating for 1:  4.289610910549539\navg. rating for 0:  4.185136031851361\n","output_type":"stream"}]},{"cell_type":"code","source":"# Using BERT embeddings on the new data\n\nfrom sklearn.decomposition import PCA\n\ndata = pd.read_csv('/kaggle/input/new-fake-reviews-swm/new_fake_reviews_data.csv')\ntexts = data['text_'][:4000].tolist()\n\n# Load pre-trained BERT model\nmodule_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\nembed = hub.KerasLayer(module_url, trainable=False)\n\n# Extract BERT embeddings\nX = embed(texts).numpy()\n\n# Using PCA\npca = PCA(n_components=50)\nX = pca.fit_transform(X)\n\n# Cluster data\nkmeans = KMeans(n_clusters=2, random_state=2)\ny_pred = kmeans.fit_predict(X)\n\nsum_1 = 0\ncount_sum_1 = 0\nsum_0 = 0\ncount_sum_0 = 0\nfor i in range(len(y_pred)):\n    if y_pred[i] == 1:\n        sum_1 = sum_1 + data['rating'][i]\n        count_sum_1 = count_sum_1 + 1\n    else:\n        sum_0 = sum_0 + data['rating'][i]\n        count_sum_0 = count_sum_0 + 1\n\nprint(\"avg. rating for 1: \", (sum_1/count_sum_1))\nprint(\"avg. rating for 0: \", (sum_0/count_sum_0))","metadata":{"execution":{"iopub.status.busy":"2023-03-20T02:01:17.929283Z","iopub.execute_input":"2023-03-20T02:01:17.929843Z","iopub.status.idle":"2023-03-20T02:07:29.132195Z","shell.execute_reply.started":"2023-03-20T02:01:17.929801Z","shell.execute_reply":"2023-03-20T02:07:29.130578Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"avg. rating for 1:  4.231863442389758\navg. rating for 0:  4.269360269360269\n","output_type":"stream"}]}]}